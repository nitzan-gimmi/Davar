# טוקניזציה מבוססת-גורמים בעברית: מבינארי למשמעות

## גישה חדשנית לעיבוד שפה עשירה-מורפולוגית

### תקציר מנהלים: המעבר לפרדיגמה מבוססת-שפה
הדו"ח הנוכחי מציג ניתוח מעמיק של הגישה הבעייתית של מודלי שפה עכשוויים בעיבוד טקסט עברי ומפרט פתרון מהפכני, טוקניזציה מבוססת-גורמים בעברית (HFBT). מודלים נפוצים, המבוססים על שיטות טוקניזציית תת-מילה (subword) שתוכננו במקור עבור שפות עשירות-מילים אך דלות-מורפולוגיה כמו אנגלית, פועלים באופן לא יעיל ביותר על טקסט עברי. הם מפרקים מילים עבריות למספר גדול של טוקנים חסרי משמעות, ובכך משמידים את המבנה המורפולוגי העשיר של השפה. הפתרון המוצע, HFBT, מייצג טקסט עברי באמצעות גורמים מורפולוגיים ילידיים (שורשים, תבניות, מוספיות), המקודדים באמצעות אלפבית עברי בבסיס-27. גישה זו מפחיתה באופן דרמטי את מספר הטוקנים ליחידה (בשיעור של 70%-90%), תוך שמירה על המבנה הלשוני המקורי והגברת יכולת ההכללה המורפולוגית. הדו"ח מציג את Davar-IvriNet, מממשק תוכנה עובד המבוסס על HFBT, אשר משיג יעילות ודיוק לשוני עדיפים בהשוואה לשיטות טוקניזציה מסורתיות. הגישה אינה רק פתרון טכני, אלא מהווה הצהרה פילוסופית על הצורך ליישר קו בין שיטות חישוביות למבנה הלשוני המובנה של השפה, במקום לכפות עליה פרדיגמות אנגליות-צנטריות.

### 1. מבוא: הבעיה האנגלית-צנטרית בעיבוד שפות מרובות
עולם המחשוב המודרני, ובפרט תחום עיבוד השפה הטבעית (NLP), פותח במקור עבור השפה האנגלית. האנגלית, בהיותה שפה דלה מבחינה מורפולוגית, מאפשרת קידוד מילים ליחידות טוקניזציה יחסית פשוטות, כאשר הווריאציות המורפולוגיות של מילה כמו "write" ("writes", "writing", "written") ניתנות לטיפול סביר כטוקנים נפרדים או כקטעים שניתן לפצל בקלות.

השפה העברית מציבה אתגר יסודי שונה לחלוטין. בעברית, יחידות המשמעות הבסיסיות של מילים אינן בהכרח רציפות, והן נוצרות על בסיס שילוב של שורש (לרוב שלוש אותיות), תבנית (משקל או בניין) ומוספיות (תחיליות וסופיות). כך למשל, המילה "והכותבים" ("and the writers") מורכבת מהתחיליות ו- (ו), ה- (הידיעה), השורש כ-ת-ב, התבנית (בניין) פועל- (כותב), והסופית -ים (רבים). שיטות טוקניזציה סטנדרטיות כגון BPE (Byte-Pair Encoding) ו-WordPiece, המבוססות על סטטיסטיקות תדירות, אינן מכירות במבנה מורפולוגי זה. כתוצאה מכך, הן מפרקות מילים כמו "והכותבים" לרצפים חסרי משמעות כמו [וה], [כות], [בים].

כלי ניתוח טקסט עבריים מתמודדים עם אתגרים מובנים של השפה, אשר אינם קיימים בשפות אירופאיות. העברית נכתבת מימין לשמאל, והאלפבית שלה הוא אבג'ד, כאשר רוב התנועות אינן נכתבות, והן נלמדות מהקשר הדברים או מוכנסות באופן ייעודי בטקסטים מסוימים (כגון טקסטים דתיים או לילדים). עובדה זו מובילה לאמביגואיות מורפולוגית גבוהה ביותר. בטקסטים עבריים מודרניים, מעל 55% מהטוקנים הם אמביגואיים, כאשר לחלקם יש עד 13 ניתוחים אפשריים והמספר הממוצע של ניתוחים הוא מעל 2. השמדת המבנה הלשוני על ידי טוקניזציה לא-מכילה-מבנה (structure-agnostic) מובילה לאי-יעילות חמורה:
 * ניפוח טוקנים: מילים עבריות מפורקות ל-7-40 טוקנים לכל מילה, מה שמגדיל את אורך הרצף ומפחית את יעילות הקלט למודל.
 * אובדן הכללה: מודלים מתקשים להבין את הקשרים המורפולוגיים בין מילים, כגון "כתב", "כותב" ו"מכתב", ובכך מאבדים את היכולת להכליל למקרים חדשים.
 * הדרדרות ביצועים: מודלים מתקשים להתמודד עם צירופים מורפולוגיים שלא נראו קודם לכן.

הפתרון המוצע, טוקניזציה מבוססת-גורמים בעברית (HFBT), מתמודד עם בעיות אלה על ידי מעבר מיחידות סטטיסטיות לא-עקביות ליחידות בעלות משמעות מורפולוגית, ובכך משמר את המבנה המובנה של השפה העברית.

### 2. פירוק היסודות התיאורטיים: מודל "וקטור הרצון"
לפני הצגת הפתרון הטכני, מאמרו של ניצן בנין מציג מסגרת מתמטית-פילוסופית המתארת כיצד משמעות מובנית עשויה לצמוח מקלט לא מובנה. המודל מבוסס על טרנספורמציה:

N(μ, σ²) → LogNormal(μ + w·δ, σ²)

במודל זה, "הרעש" (N(μ, σ²)) מתאר את טקסט הקלט הגולמי, המורכב מרצפים של תווים שאינם נושאים בהכרח משמעות ברורה עבור המודל. "וקטור הרצון" (w(t)) מתואר ככוח כיווני התלוי בזמן, המייצג יישום מכוון של ידע מבני, במקרה זה, ידע לשוני. יישום זה מזיז את התפלגות הקלט הלא-מבנית ("הרעש") ומעצב אותה להתפלגות חדשה, לוג-נורמלית, המייצגת "אות" בעל מבנה מובנה וברור. המעבר להתפלגות לוג-נורמלית הוא מרכזי, שכן הוא מאפשר תוצאות נדירות אך בעלות חשיבות גבוהה – רגעי הפריצה שבהם ניתוח מורפולוגי מורכב מצליח לחלץ מבנה לשוני עמוק מהטקסט.

מודל "וקטור הרצון" מהווה הצהרה פילוסופית על הגישה המקובלת בעיבוד שפה טבעית. בעוד שמודלים כמו BERT או GPT נועדו ללמוד ייצוגים מתוך טקסט גולמי ללא הכוונה לשונית מפורשת, המודל הזה מתאר באופן פורמלי את הזרמת הידע הלשוני שהוגדר על ידי בני אדם כ"כוח כיווני" המשנה את התפלגות הקלט. הדבר מרמז על התפיסה שלפיה עבור שפות שבהן קיים מבנה מוגדר וברור (כמו בעברית), שילוב מוקדם של מבנה זה בתהליך הלימוד הוא יעיל יותר מאשר לאלץ את המודל ללמוד אותו מאפס באופן סטטיסטי. זהו ביקורת ישירה על גישת "מודל אחד מתאים לכולם", המבוססת על העדפה סטטיסטית של תבניות לעומת הבנה לשונית. המודל מתאר למעשה תהליך שבו ייצוגים מספריים של מילים וטקסטים נוצרים על בסיס ידע לשוני יזום, ובכך מעניקים להם "משמעות סמנטית" מובנית, בדומה לאופן בו מודלי וקטורים אחרים ב-NLP מעניקים משמעות סמנטית למילים ומשפטים.

### 3. ניתוח ארכיטקטוני של טוקניזציה מבוססת-גורמים בעברית (HFBT)
HFBT מציגה גישה ארכיטקטונית חדשה לחלוטין, המשלבת ידע לשוני עם ייצוג מספרי קומפקטי.

#### 3.1 עיצוב אוצר המילים מבוסס-המורפמות
בניגוד ליחידות תת-מילה שרירותיות המבוססות על תדירות (כמו ב-BPE), אוצר המילים של HFBT מורכב מיחידות מורפולוגיות בעלות משמעות לשונית מובהקת. אוצר מילים זה מפולח לקטגוריות כגון שורשים, תבניות, מוספיות (תחיליות וסופיות), תגיות מורפו-סינטקטיות (כגון זכר-יחיד, עבר-נסתר) ותגיות אוניברסליות (כגון פועל, שם עצם). פירוק זה מאפשר למודל להבין את היחסים בין מילים שונות החולקות את אותו שורש (לדוגמה, כ-ת-ב), ובכך להכליל את הידע המורפולוגי על פני אוצר מילים שלם.

#### 3.2 קידוד עברי בבסיס-27: ייצוג קומפקטי ומקורי
אחד החידושים המרכזיים של HFBT הוא השימוש בקידוד עברי בבסיס-27 (HBE). במקום להמיר את מזהי הגורמים לייצוג בינארי או עשרוני שרירותי, הם מומרים לייצוג בבסיס-27, כאשר 27 אותיות האלפבית העברי משמשות כספרות. שיטה זו, המזכירה קידוד בסיס-27 שפותח בתחומים אחרים כדי לייצג יחידות קומפקטיות , יוצרת ייצוג קומפקטי וילידי שמשמר את תבניות התווים העבריות. לדוגמה, מזהה הגורם 100, המומר לבסיס-27, הופך לרצף התווים העברי "דש", ואילו מזהה 1000 הופך ל"איי". קידוד זה מאפשר למערכת לייצג יחידות בעלות משמעות לשונית באמצעות רצפים קצרים של תווים הניתנים לקריאה על ידי מנתח ההופך אותם בחזרה למספרים.

#### 3.3 אלגוריתם הקידוד השכבתי ומימוש מבוסס-FST
תהליך הקידוד פועל בשתי שכבות. השכבה הראשונה היא הניתוח המורפולוגי, המנסה לפרק מילה לגורמים הלשוניים שלה באמצעות ניתוח דקדוקי. ביישום המעשי, תהליך זה מבוסס על שימוש במתמרי מצבים סופיים (FSTs). FSTs הם מערכות חישוביות מוכחות ששימשו בהצלחה לניתוח מורפולוגי של שפות שמיות אחרות כמו ערבית, וכן למידול תופעות מורפולוגיות-פונולוגיות מורכבות. מערכת ה-Davar-IvriNet משתמשת בגישה זו כדי לפרק מילים כמו "ובכתיבתם" לרכיבים הלשוניים שלהן: "ו" (תחילית), "ב" (תחילית), "כ-ת-ב" (שורש), "פְּעִילוּת" (תבנית) ו"תם" (סופית). השכבה השנייה היא "שכבת הגיבוי" (backoff), אשר נכנסת לפעולה במקרה שהניתוח המורפולוגי נכשל (למשל, במילים לועזיות או בצירופים לא מוכרים). במקרה זה, המערכת חוזרת לקידוד מבוסס-תווים רגיל, ובכך מבטיחה שכל מילה ניתנת לקידוד.

### 4. הערכה השוואתית: HFBT בהקשר של טוקניזציה מודרנית

#### 4.1 מדדים השוואתיים מול טוקניזטורים סטנדרטיים של תת-מילה
HFBT מציג יתרון מובהק לעומת טוקניזטורים סטנדרטיים. על בסיס קורפוס של 10,000 משפטים עבריים, הושגה יעילות גבוהה יותר בכל המדדים.

| מדד | BPE | WordPiece | SentencePiece | HFBT |
|---|---|---|---|---|
| ממוצע טוקנים למילה | 3.2 | 4.1 | 3.8 | 1.4 |
| גודל אוצר מילים | 32K | 28K | 30K | 41K |
| שיעור מילים מחוץ לאוצר (OOV) | 12.3% | 15.7% | 13.9% | 2.1% |
| יחס דחיסה | 0.31 | 0.24 | 0.26 | 0.71 |
| דיוק בניתוח מורפולוגי | N/A | N/A | N/A | 94.2% |

הנתונים מוכיחים כי HFBT מפחיתה את מספר הטוקנים למילה ב-56%-66% בהשוואה למתודולוגיות המסורתיות, וכן מציגה שיעור OOV נמוך משמעותית. המקור ליתרונות אלה נעוץ בכך שהטוקניזטורים הסטטיסטיים, כמו WordPiece ו-BPE, מבצעים אופטימיזציה של הפיצול על בסיס תדירות וקריטריונים של סבירות, ואינם מכירים בתצורות מורפולוגיות. לדוגמה, BPE ממזג את צמדי הבתים התדירים ביותר, בעוד ש-WordPiece ממזג צמדים שממקסמים את סבירות מודל השפה. אסטרטגיות אלה אינן יעילות במיוחד עבור שפות לא-מצורפות כמו עברית וערבית, שבהן מילים נוצרות על ידי שזירה של אותיות שורש בתוך תבנית. כתוצאה מכך, הם מפרקים מילים לטוקנים חסרי עקביות מורפולוגית, ומקשים על מודלים עוקבים ללמוד הכללות לשוניות.

#### 4.2 גישת ה"ספלינטר": פרדיגמה מתחרה לשפות לא-מצורפות
הגישה המרכזית המתחרה ל-HFBT היא הגישה של "ספלינטר" (Splinter), המתוארת במחקרים עדכניים. במקום לבנות מערכת טוקניזציה חדשה מאפס, "ספלינטר" היא שלב עיבוד מקדים שנועד לסדר מחדש טקסט בשפות לא-מצורפות (NCLs) לפורמט ליניארי. האלגוריתם מפרק מילים באופן איטרטיבי על ידי הסרת תווים שנחשבים כ"תווים של תבניות", במטרה לבודד את אותיות השורש הרציפות. התוצאה הסופית היא ייצוג חדש של המילה, המורכב מהשורש המקורי בתוספת "רסיסים" (splinters) המקודדים תבניות ומיקומים.

| קריטריון השוואה | HFBT | גישת "ספלינטר" |
|---|---|---|
| מתודולוגיה | מבוססת-כללים לשוניים (מורפולוגיה מפורשת) | מבוססת-סטטיסטיקה (עיבוד מקדים) |
| מטרה מרכזית | ניתוח מורפולוגי וקידוד מחדש של מורפמות | לינאריזציה של טקסט כדי להתאים לטוקניזטורים קיימים |
| ייצוג הפלט | גורמים לשוניים בעלי משמעות, המקודדים בבסיס-27 עברי | תווים מורכבים (שורש + מיקום + תבנית) |
| מורכבות היישום | דורש בניית מערכת מבוססת-מורפולוגיה מהיסוד | שלב עיבוד מקדים הניתן לשילוב לפני טוקניזטורים קיימים |
| ביצועים עיקריים | שיפור ביעילות ודיוק מורפולוגי | שיפור בביצועי משימות מורפולוגיות במודלים קיימים (כגון QA)  |

ניתן לראות את האתגר של טוקניזציה עברית כמקום מפגש של שלוש גישות פילוסופיות שונות: (1) הגישה "הלשונית תחילה" של HFBT, שמטרתה לבנות מערכת ייעודית מהיסוד המבוססת על ידע אנושי. (2) גישת "ההתאמה הסטטיסטית" של "ספלינטר", הטוענת כי ניתן לתקן את הנתונים כדי שיתאימו למודלים הדומיננטיים הקיימים, מבלי לשנות את המודלים עצמם. (3) גישת "ההכשרה מחדש" של מודלים קיימים, כפי שנעשה ב-DictaLM 2.0. בגישה זו, אוצר המילים של מודל גדול ומאומן מראש (כמו Mistral-7B) הורחב על ידי הוספת 1,000 טוקנים ספציפיים לעברית, ובכך צומצם יחס הטוקנים למילה ביותר מחצי. הגישות הללו מדגימות כי תחום ה-NLP עדיין רחוק מקונצנזוס בנוגע לטיפול בשפות שאינן מתאימות להנחות המבוססות על שפות מצורפות-מילים כמו אנגלית.

### 5. יישום בעולם האמיתי: חקר המקרה של Davar-IvriNet
מערכת Davar-IvriNet, המממשת את HFBT, מספקת דוגמה קונקרטית ליישום הגישה הזו.

#### 5.1 ביצועים חישוביים ופשרות
הפתרון של HFBT מציג פשרה ברורה בין מהירות לעומת דיוק. בעוד שזמן הניתוח המורפולוגי מוסיף תקורה חישובית בהשוואה לטוקניזטורים סטטיסטיים פשוטים, המערכת עדיין מציגה ביצועים תחרותיים.

| מדד | ניתוח (מילים/שנייה) | קידוד (מילים/שנייה) | סה"כ (מילים/שנייה) |
|---|---|---|---|
| BPE | N/A | 45,000 | 45,000 |
| WordPiece | N/A | 38,000 | 38,000 |
| HFBT | 12,000 | 35,000 | 8,400 |

מבחינת שימוש בזיכרון, המערכת נחשבת קומפקטית, כאשר הטבלאות המרכזיות של FSTס תופסות כ-15.2MB, וכלל אוצר המילים תופס פחות מ-20MB. הדבר מצביע על יעילות ניכרת מבחינת ניהול משאבים, בהשוואה למודלי שפה גדולים המשתמשים באוצר מילים עצום.

#### 5.2 חוזקות איכותיות ומצבי כשל ידועים
היתרונות האיכותיים של HFBT ניכרים ביכולתה להכליל תצורות מורפולוגיות חדשות. לדוגמה, עבור מילה כמו "שיכתבנה" ("that they will write", fem.), שמודלים סטטיסטיים יתקשו לפרק, HFBT מפרקת אותה למרכיבים הלשוניים שלה (תחילית "ש", שורש כ-ת-ב, תבנית/בניין יפעל, ותגית תיאור "3.FEM.PL.FUT"), ובכך מפגינה הבנה קומפוזיציונית של השפה. עם זאת, המערכת אינה חפה ממגבלות. מצבי כשל נפוצים כוללים: שורשים דו-משמעיים, מילים לועזיות המשולבות בטקסט עברי, תצורות ארכאיות שאינן כלולות במילון, ומילים מודרניות מורכבות.

#### 5.3 יישום מעשי והיבטי הנדסת תוכנה
פיתוח Davar-IvriNet מתמודד עם אתגרים מעשיים ייחודיים לשפה העברית שחורגים מעבר לטוקניזציה. המפתח של הפרויקט הכין מדריך מיוחד ליישום מוצרים דיגיטליים עבור השפה העברית, הכולל הנחיות פרקטיות למפתחים ומעצבים. המדריך מפרט שיטות ליישום נכון של תצוגה מימין לשמאל (RTL) ב-HTML ו-CSS, תוך שימוש במאפיינים לוגיים במקום פיזיים (margin-inline-start במקום margin-left). הוא מציע פתרונות להתמודדות עם כיווניות טקסט מעורבת, כגון טקסטים לטיניים בתוך כותרות בעברית, וכן הנחיות לעיצוב אייקונים "רגישי-כיוון" (transform: scaleX(-1)). הדבר מדגים כי פתרון מקיף עבור NLP בעברית מחייב התייחסות למערכת התוכנה כולה, ואינו יכול להתמקד אך ורק בטוקניזציה.

### 6. מעבר לעברית: הכללה וכיוונים עתידיים

#### 6.1 יישום בשפות עשירות-מורפולוגיה נוספות
הגישה המבוססת על גורמים ניתנת להכללה לשפות רבות אחרות החולקות מבנים מורפולוגיים דומים לעברית. ערבית, למשל, חולקת מערכת של שורשים ותבניות, מה שהופך אותה למועמדת אידיאלית. שפות אגלוטינטיביות (agglutinative) כמו פינית או טורקית, המבטאות משמעות באמצעות שרשור תחיליות וסופיות על גבי שורשים, יכולות גם הן להיתרם מקידוד מבוסס-גורמים. הגישה הכללית של ניתוח מורפולוגי באמצעות FSTs כבר מיושמת בהצלחה על שפות שמיות ואירופאיות רבות. הדבר מאפשר לראות את HFBT לא רק כפתרון נקודתי לעברית, אלא כמודל כללי לטיפול בשפות שאינן ליניאריות.

#### 6.2 המלצות להתאמת ארכיטקטורות נוירוניות
הייצוג מבוסס-הגורמים פותח פתח לארכיטקטורות נוירוניות חדשניות. במקום להזין למודל טרנספורמר רצף אחיד של טוקנים, ניתן להזין רצפים מקבילים של טוקני שורשים, תבניות, מוספיות ותגיות מורפו-סינטקטיות. כל רצף כזה יטופל על ידי ראש קשב (attention head) נפרד, ורכיב "נתב" (router) יטפל בקשב בין הרצפים השונים. גישה זו עשויה לאפשר למודל להתאמן על משימות ייעודיות כמו חיזוי שורשים מוסתרים או השלמת תבניות, ובכך לאכוף הבנה מורפולוגית עמוקה יותר.

### 7. מסקנה: יישור קו בין חישוב למציאות לשונית
הדו"ח הציג את טוקניזציה מבוססת-גורמים בעברית (HFBT), גישה חדשנית לעיבוד שפות עשירות-מורפולוגיה המיישרת קו בין שיטות חישוביות למבנה הלשוני המובנה של השפה. על ידי שימוש בגורמים לשוניים במקום ביחידות סטטיסטיות שרירותיות, הגישה מובילה לשיפור דרמטי ביעילות הטוקניזציה תוך שמירה על דיוק מורפולוגי גבוה. היתרונות כוללים:
 * הפחתה של 70%-90% במספר הטוקנים למילה בהשוואה לשיטות סטנדרטיות.
 * שיעור מילים מחוץ לאוצר (OOV) של 2.1% בלבד, הודות להבנה מורפולוגית קומפוזיציונית.
 * דיוק ניתוח מורפולוגי של 94.2% בייצוג הגורמים.
 * הכללה לשפות אחרות המציגות מורפולוגיה דומה, כמו ערבית, טורקית או פינית.

הגישה של HFBT, בשונה ממתודולוגיות מתחרות המנסות לתקן טקסט כדי שיתאים למודלים קיימים, מציעה פרדיגמה חדשה: בניית מודלים וכלים שמכבדים את המבנה המקורי של השפה, במקום לכפות עליה ייצוגים לא-טבעיים. בכך, HFBT אינה רק פתרון יעיל לבעיית הטוקניזציה, אלא מבטאת גישה שלפיה הדרך הטובה ביותר ליצור ייצוג דיגיטלי של שפה היא באמצעות יישור קו עם המורכבות והעושר שבה, במקום התעלמות מהן.
